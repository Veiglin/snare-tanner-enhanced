{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import sqlite3\n",
    "from reportlab.pdfgen import canvas\n",
    "\n",
    "def generate_pdf(file_path, tracking_url):\n",
    "    \"\"\"\n",
    "    Generate a PDF with an embedded remote image for tracking.\n",
    "    The image is drawn at an invisible 1x1 pixel size.\n",
    "    \"\"\"\n",
    "    c = canvas.Canvas(file_path)\n",
    "    # Draw an image from the tracking URL (assumes the PDF viewer loads remote images)\n",
    "    c.drawImage(tracking_url, 0, 0, width=1, height=1, mask='auto')\n",
    "    c.showPage()\n",
    "    c.save()\n",
    "    print(f\"PDF honeytoken generated: {file_path}\")\n",
    "\n",
    "def generate_sql(file_path, tracking_url):\n",
    "    \"\"\"\n",
    "    Generate a SQL file with a comment that includes the tracking URL.\n",
    "    Note: This does not auto-trigger an HTTP request.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(\"-- Honeytoken SQL file\\n\")\n",
    "        f.write(f\"-- Remote Tracker: {tracking_url}\\n\")\n",
    "        f.write(\"SELECT 'Honeytoken';\\n\")\n",
    "    print(f\"SQL honeytoken generated: {file_path}\")\n",
    "\n",
    "def generate_zip(file_path, tracking_url):\n",
    "    \"\"\"\n",
    "    Generate a ZIP file that contains an HTML file.\n",
    "    The HTML file embeds a remote image, so if the HTML is opened in a browser,\n",
    "    the image request can be logged.\n",
    "    \"\"\"\n",
    "    html_content = f\"\"\"<html>\n",
    "  <body>\n",
    "    <img src=\"{tracking_url}\" width=\"1\" height=\"1\" alt=\"tracker\" />\n",
    "    <p>This is a honeytoken contained within a zip file.</p>\n",
    "  </body>\n",
    "</html>\"\"\"\n",
    "    # Create a temporary HTML file\n",
    "    tmp_html = \"tracker.html\"\n",
    "    with open(tmp_html, \"w\") as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    # Package the HTML file in a ZIP archive\n",
    "    with zipfile.ZipFile(file_path, \"w\") as zipf:\n",
    "        zipf.write(tmp_html)\n",
    "    os.remove(tmp_html)\n",
    "    print(f\"ZIP honeytoken generated: {file_path}\")\n",
    "\n",
    "def generate_db(file_path, tracking_url):\n",
    "    \"\"\"\n",
    "    Generate a dummy SQLite database file.\n",
    "    We create a table and insert a row that includes the tracking URL.\n",
    "    While opening the DB won’t automatically trigger a remote request,\n",
    "    the URL will be embedded as a traceable record.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(file_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"CREATE TABLE IF NOT EXISTS honeytoken (id INTEGER PRIMARY KEY, info TEXT)\")\n",
    "    c.execute(\"INSERT INTO honeytoken (info) VALUES (?)\", (f\"Remote Tracker: {tracking_url}\",))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"DB honeytoken generated: {file_path}\")\n",
    "\n",
    "def generate_bak(file_path, tracking_url):\n",
    "    \"\"\"\n",
    "    Generate a backup file (BAK) that contains a hidden tracking URL in plain text.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(\"This is a honeytoken backup file.\\n\")\n",
    "        f.write(f\"Remote Tracker: {tracking_url}\\n\")\n",
    "    print(f\"BAK honeytoken generated: {file_path}\")\n",
    "\n",
    "def generate_honeytoken_file(file_name, tracking_url):\n",
    "    \"\"\"\n",
    "    Dispatch to the correct generator based on file extension.\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(file_name)[1].lower()\n",
    "    if ext == \".pdf\":\n",
    "        generate_pdf(file_name, tracking_url)\n",
    "    elif ext == \".sql\":\n",
    "        generate_sql(file_name, tracking_url)\n",
    "    elif ext == \".zip\":\n",
    "        generate_zip(file_name, tracking_url)\n",
    "    elif ext == \".db\":\n",
    "        generate_db(file_name, tracking_url)\n",
    "    elif ext == \".bak\":\n",
    "        generate_bak(file_name, tracking_url)\n",
    "    else:\n",
    "        # For any other file type, write a simple text file with the tracking URL.\n",
    "        with open(file_name, \"w\") as f:\n",
    "            f.write(f\"Remote Tracker: {tracking_url}\\n\")\n",
    "        print(f\"Generic honeytoken generated: {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your unique tracking URL, e.g., pointing to your server’s tracking endpoint.\n",
    "tracking_url = \"https://yourserver.com/tracker?token=unique_honeytoken_id\"\n",
    "\n",
    "# List of bait file names you want to generate.\n",
    "filenames = [\"bait_document.pdf\", \"sensitive_export.sql\", \"backup.zip\", \"internal.db\", \"config.bak\"]\n",
    "\n",
    "for fn in filenames:\n",
    "    generate_honeytoken_file(fn, tracking_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find stream length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Use a unique hostname such as b'unique1234.honeytoken.yourdomain.com'\u001b[39;00m\n\u001b[1;32m     51\u001b[0m unique_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://.smartgadgetstore.live/robots.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 52\u001b[0m modified_pdf \u001b[38;5;241m=\u001b[39m \u001b[43mmake_custom_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_hostname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhoneytoken.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     54\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(modified_pdf)\n",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m, in \u001b[0;36mmake_custom_pdf\u001b[0;34m(hostname, template, stream_offset)\u001b[0m\n\u001b[1;32m     23\u001b[0m stream_size_match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/Length ([0-9]+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/.*\u001b[39m\u001b[38;5;124m\"\u001b[39m, contents[stream_offset:])\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream_size_match:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find stream length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m stream_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(stream_size_match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Find where the stream starts (after 'stream\\r\\n')\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find stream length"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "STREAM_OFFSET = 100  # Example offset; you must determine this based on your template\n",
    "\n",
    "def substitute_stream(header: bytes, stream: bytes, replace: bytes):\n",
    "    # This helper function would locate the placeholder within the stream\n",
    "    # and substitute it with your unique token (e.g., a hostname).\n",
    "    # (Implementation details depend on your PDF template.)\n",
    "    new_stream = stream.replace(b\"Top\", replace)\n",
    "    return header, new_stream\n",
    "\n",
    "def make_custom_pdf(hostname: bytes, \n",
    "                    template: Path, \n",
    "                    stream_offset: int = STREAM_OFFSET):\n",
    "    \n",
    "    # Read the template PDF as binary\n",
    "    with open(template, \"rb\") as fp:\n",
    "        contents = fp.read()\n",
    "    \n",
    "    # Extract stream length using regex on a slice from the stream offset\n",
    "    stream_size_match = re.match(rb\".*\\/Length ([0-9]+)\\/.*\", contents[stream_offset:])\n",
    "    if not stream_size_match:\n",
    "        raise ValueError(\"Could not find stream length\")\n",
    "    stream_size = int(stream_size_match.group(1))\n",
    "    \n",
    "    # Find where the stream starts (after 'stream\\r\\n')\n",
    "    stream_start = stream_offset + contents[stream_offset:].index(b\"stream\\r\\n\") + 8\n",
    "    stream_header = contents[stream_offset:stream_start]\n",
    "    stream = contents[stream_start: stream_start + stream_size]\n",
    "    \n",
    "    # Substitute the placeholder with your hostname\n",
    "    new_header, new_stream = substitute_stream(header=stream_header, stream=stream, replace=hostname)\n",
    "    \n",
    "    # Reassemble the PDF contents with the modified stream\n",
    "    output = BytesIO()\n",
    "    output.write(contents[0:stream_offset])\n",
    "    output.write(new_header)\n",
    "    output.write(new_stream)\n",
    "    output.write(contents[stream_start + stream_size:])\n",
    "    new_contents = output.getvalue()\n",
    "    output.close()\n",
    "    \n",
    "    return new_contents\n",
    "\n",
    "# Example usage:\n",
    "template_path = Path(\"pdf_template.pdf\")\n",
    "\n",
    "# Use a unique hostname such as b'unique1234.honeytoken.yourdomain.com'\n",
    "unique_hostname = b\"https://.smartgadgetstore.live/robots.txt\"\n",
    "modified_pdf = make_custom_pdf(unique_hostname, template_path)\n",
    "with open(\"honeytoken.pdf\", \"wb\") as f:\n",
    "    f.write(modified_pdf)\n",
    "print(\"Honeytoken PDF created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream size: 183, Stream start: 539, Stream end: 724\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 95\u001b[0m\n\u001b[1;32m     92\u001b[0m tracking_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://smartgadgetstore.live/robots.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Generate the modified PDF\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m modified_pdf \u001b[38;5;241m=\u001b[39m \u001b[43mmake_canary_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracking_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     97\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(modified_pdf)\n",
      "Cell \u001b[0;32mIn[8], line 73\u001b[0m, in \u001b[0;36mmake_canary_pdf\u001b[0;34m(hostname, template, stream_offset)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStream size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstream_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Stream start: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstream_start\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Stream end: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstream_end\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Replace the placeholder in the stream with the tracking URL\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m stream_header, stream \u001b[38;5;241m=\u001b[39m \u001b[43m_substitute_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_header\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhostname\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Reassemble the PDF with the modified stream\u001b[39;00m\n\u001b[1;32m     78\u001b[0m output \u001b[38;5;241m=\u001b[39m BytesIO()\n",
      "Cell \u001b[0;32mIn[8], line 30\u001b[0m, in \u001b[0;36m_substitute_stream\u001b[0;34m(header, stream, replace, search)\u001b[0m\n\u001b[1;32m     27\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(candidate_stream) \u001b[38;5;241m<\u001b[39m old_len \u001b[38;5;129;01mand\u001b[39;00m count \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10000\u001b[39m:\n\u001b[1;32m     29\u001b[0m     padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m---> 30\u001b[0m         \u001b[43m[\u001b[49m\u001b[38;5;28;43mchr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandrange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m65\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     31\u001b[0m     )\u001b[38;5;241m.\u001b[39mencode()\n\u001b[1;32m     32\u001b[0m     candidate_stream \u001b[38;5;241m=\u001b[39m zlib\u001b[38;5;241m.\u001b[39mcompress(\n\u001b[1;32m     33\u001b[0m         zlib\u001b[38;5;241m.\u001b[39mdecompress(stream)\u001b[38;5;241m.\u001b[39mreplace(search, replace \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m padding)\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     35\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[8], line 30\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(candidate_stream) \u001b[38;5;241m<\u001b[39m old_len \u001b[38;5;129;01mand\u001b[39;00m count \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10000\u001b[39m:\n\u001b[1;32m     29\u001b[0m     padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m---> 30\u001b[0m         [\u001b[38;5;28mchr\u001b[39m(random\u001b[38;5;241m.\u001b[39mrandrange(\u001b[38;5;241m65\u001b[39m, \u001b[38;5;241m90\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(count)]\n\u001b[1;32m     31\u001b[0m     )\u001b[38;5;241m.\u001b[39mencode()\n\u001b[1;32m     32\u001b[0m     candidate_stream \u001b[38;5;241m=\u001b[39m zlib\u001b[38;5;241m.\u001b[39mcompress(\n\u001b[1;32m     33\u001b[0m         zlib\u001b[38;5;241m.\u001b[39mdecompress(stream)\u001b[38;5;241m.\u001b[39mreplace(search, replace \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m padding)\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     35\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import zlib\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "STREAM_OFFSET = 100  # Adjust this based on your PDF template\n",
    "\n",
    "def _substitute_stream(\n",
    "    header,\n",
    "    stream: bytes,\n",
    "    replace: bytes,\n",
    "    search: bytes = b\"abcdefghijklmnopqrstuvwxyz.zyxwvutsrqponmlkjihgfedcba.aceegikmoqsuwy.bdfhjlnprtvxz\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Replace a placeholder in the PDF stream with the tracking URL.\n",
    "    Ensures the modified stream is the same size as the original.\n",
    "    \"\"\"\n",
    "    MAX_ATTEMPTS = 100\n",
    "    old_len = len(stream)\n",
    "    attempts = 0\n",
    "\n",
    "    while attempts < MAX_ATTEMPTS:\n",
    "        candidate_stream = zlib.compress(\n",
    "            zlib.decompress(stream).replace(search, replace)\n",
    "        )\n",
    "        count = 1\n",
    "        while len(candidate_stream) < old_len and count < 10000:\n",
    "            padding = \"\".join(\n",
    "                [chr(random.randrange(65, 90)) for _ in range(count)]\n",
    "            ).encode()\n",
    "            candidate_stream = zlib.compress(\n",
    "                zlib.decompress(stream).replace(search, replace + b\"/\" + padding)\n",
    "            )\n",
    "            count += 1\n",
    "        if len(candidate_stream) == old_len:\n",
    "            break\n",
    "        attempts += 1\n",
    "\n",
    "    if attempts == MAX_ATTEMPTS:\n",
    "        raise Exception(\n",
    "            f\"Failed to adjust stream size after {MAX_ATTEMPTS} attempts.\"\n",
    "        )\n",
    "\n",
    "    return header, candidate_stream\n",
    "\n",
    "\n",
    "def make_canary_pdf(\n",
    "    hostname: bytes, template: Path, stream_offset: int = STREAM_OFFSET\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a PDF with an embedded tracking URL.\n",
    "    \"\"\"\n",
    "    with open(template, \"rb\") as fp:\n",
    "        contents = fp.read()\n",
    "\n",
    "    # Dynamically locate the /Length property in the PDF content\n",
    "    length_match = re.search(rb\"/Length (\\d+)\", contents)\n",
    "    if not length_match:\n",
    "        raise ValueError(\"Could not find stream length in the PDF template.\")\n",
    "    stream_size = int(length_match.group(1))\n",
    "\n",
    "    stream_start = stream_offset + contents[stream_offset:].index(b\"stream\\r\\n\") + 8\n",
    "    stream_header = contents[stream_offset:stream_start]\n",
    "    # Extract the stream data up to the 'endstream' marker to ensure completeness\n",
    "    stream_end = stream_start + stream_size\n",
    "    if b\"endstream\" in contents[stream_start:]:\n",
    "        stream_end = stream_start + contents[stream_start:].index(b\"endstream\")\n",
    "    stream = contents[stream_start:stream_end]\n",
    "    \n",
    "    print(f\"Stream size: {stream_size}, Stream start: {stream_start}, Stream end: {stream_end}\")\n",
    "    # Replace the placeholder in the stream with the tracking URL\n",
    "    stream_header, stream = _substitute_stream(\n",
    "        header=stream_header, stream=stream, replace=hostname\n",
    "    )\n",
    "\n",
    "    # Reassemble the PDF with the modified stream\n",
    "    output = BytesIO()\n",
    "    output.write(contents[:stream_offset])\n",
    "    output.write(stream_header)\n",
    "    output.write(stream)\n",
    "    output.write(contents[stream_start + stream_size:])\n",
    "    new_contents = output.getvalue()\n",
    "    output.close()\n",
    "\n",
    "    return new_contents\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/nicolaiveiglinarends/dtu-honeypot-thesis/snare/snare/tests/pdf_template_token.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 89\u001b[0m\n\u001b[1;32m     86\u001b[0m tracking_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://smartgadgetstore.live/pdf_template.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Generate the modified PDF\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m modified_pdf \u001b[38;5;241m=\u001b[39m \u001b[43mmake_canary_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracking_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     91\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(modified_pdf)\n",
      "Cell \u001b[0;32mIn[1], line 59\u001b[0m, in \u001b[0;36mmake_canary_pdf\u001b[0;34m(hostname, template, stream_offset)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_canary_pdf\u001b[39m(\n\u001b[1;32m     57\u001b[0m     hostname: \u001b[38;5;28mbytes\u001b[39m, template: Path, stream_offset: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m STREAM_OFFSET\n\u001b[1;32m     58\u001b[0m ):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m     60\u001b[0m         contents \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     62\u001b[0m     stream_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\n\u001b[1;32m     63\u001b[0m         re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/Length ([0-9]+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/.*\u001b[39m\u001b[38;5;124m\"\u001b[39m, contents[stream_offset:])\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     64\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/my_environment/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/nicolaiveiglinarends/dtu-honeypot-thesis/snare/snare/tests/pdf_template_token.pdf'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import zlib\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "#from canarytokens.constants import CANARY_PDF_TEMPLATE_OFFSET as STREAM_OFFSET\n",
    "\n",
    "# PDF_FILE=settings.CANARY_PDF_TEMPLATE\n",
    "# STREAM_OFFSET=settings.CANARY_PDF_TEMPLATE_OFFSET\n",
    "STREAM_OFFSET = 793\n",
    "# CANARY_PDF_TEMPLATE_OFFSET=793\n",
    "\n",
    "\n",
    "def _substitute_stream(\n",
    "    header,\n",
    "    stream: bytes,\n",
    "    replace: bytes,\n",
    "    search: bytes = b\"abcdefghijklmnopqrstuvwxyz.zyxwvutsrqponmlkjihgfedcba.aceegikmoqsuwy.bdfhjlnprtvxz\",\n",
    "):\n",
    "    # Ohhhh, this is nasty. Instead of trying to get the xref positions right,\n",
    "    # we're going to brute-force a URL that's the right size after compression.\n",
    "    # Give up after 100 attempts.\n",
    "\n",
    "    MAX_ATTEMPTS = 100\n",
    "\n",
    "    old_len = len(stream)\n",
    "    attempts = 0\n",
    "    while attempts < MAX_ATTEMPTS:\n",
    "        candidate_stream = zlib.compress(\n",
    "            zlib.decompress(stream).replace(search, replace)\n",
    "        )\n",
    "        count = 1\n",
    "        while len(candidate_stream) < old_len and count < 10000:\n",
    "            padding = \"\".join(\n",
    "                [chr(random.randrange(65, 90)) for x in range(0, count)]\n",
    "            ).encode()\n",
    "            candidate_stream = zlib.compress(\n",
    "                zlib.decompress(stream).replace(search, replace + b\"/\" + padding)\n",
    "            )\n",
    "            count += 1\n",
    "        if old_len == len(candidate_stream):\n",
    "            break\n",
    "        attempts += 1\n",
    "\n",
    "    if attempts == MAX_ATTEMPTS:\n",
    "        raise Exception(\n",
    "            \"Dammit, new PDF is too big after {attempts} attempts, ({new_len} > {old_len})\".format(\n",
    "                attempts=attempts, new_len=len(candidate_stream), old_len=old_len\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return (header, candidate_stream)\n",
    "\n",
    "\n",
    "def make_canary_pdf(\n",
    "    hostname: bytes, template: Path, stream_offset: int = STREAM_OFFSET\n",
    "):\n",
    "    with open(template, \"rb\") as fp:\n",
    "        contents = fp.read()\n",
    "\n",
    "    stream_size = int(\n",
    "        re.match(rb\".*\\/Length ([0-9]+)\\/.*\", contents[stream_offset:]).group(1)\n",
    "    )\n",
    "    stream_start = stream_offset + contents[stream_offset:].index(b\"stream\\r\\n\") + 8\n",
    "    stream_header = contents[stream_offset:stream_start]\n",
    "    stream = contents[stream_start : stream_start + stream_size]  # noqa: E203\n",
    "\n",
    "    (stream_header, stream) = _substitute_stream(\n",
    "        header=stream_header, stream=stream, replace=hostname\n",
    "    )\n",
    "\n",
    "    output = BytesIO()\n",
    "    output.write(contents[0:stream_offset])\n",
    "    output.write(stream_header)\n",
    "    output.write(stream)\n",
    "    output.write(contents[stream_start + stream_size :])  # noqa: E203\n",
    "    new_contents = output.getvalue()\n",
    "    output.close()\n",
    "\n",
    "    return new_contents\n",
    "\n",
    "# Example usage\n",
    "template_path = Path(\"/Users/nicolaiveiglinarends/dtu-honeypot-thesis/snare/snare/tests/pdf_template_token.pdf\")\n",
    "output_path = Path(\"/Users/nicolaiveiglinarends/dtu-honeypot-thesis/snare/snare/tests/honeytoken.pdf\")\n",
    "tracking_url = b\"https://smartgadgetstore.live/pdf_template.pdf\"\n",
    "\n",
    "# Generate the modified PDF\n",
    "modified_pdf = make_canary_pdf(tracking_url, template_path)\n",
    "with open(output_path, \"wb\") as f:\n",
    "    f.write(modified_pdf)\n",
    "\n",
    "print(f\"Honeytoken PDF created: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Honeytoken PDF created: /Users/nicolaiveiglinarends/dtu-honeypot-thesis/snare/snare/tests/honeytoken.pdf\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import zlib\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the offset where the target content stream begins in your template.\n",
    "STREAM_OFFSET = 793  # Adjust based on your PDF template\n",
    "\n",
    "def substitute_stream(header: bytes, stream: bytes, replacement: bytes,\n",
    "                      placeholder: bytes = b\"PLACEHOLDER_TOKEN\") -> (bytes, bytes):\n",
    "    \"\"\"\n",
    "    Decompress the given PDF stream, replace a placeholder with the replacement,\n",
    "    and then recompress while attempting to match the original stream length.\n",
    "\n",
    "    If the new compressed stream is shorter than the original, we pad the decompressed\n",
    "    data (with spaces) until the recompressed length equals the original.\n",
    "    \"\"\"\n",
    "    original_length = len(stream)\n",
    "    # Decompress the original stream data\n",
    "    try:\n",
    "        decompressed = zlib.decompress(stream)\n",
    "    except zlib.error as e:\n",
    "        raise Exception(\"Error decompressing PDF stream\") from e\n",
    "\n",
    "    # Replace the placeholder in the decompressed data\n",
    "    new_decompressed = decompressed.replace(placeholder, replacement)\n",
    "\n",
    "    # If the replacement makes the decompressed data shorter, pad it with spaces.\n",
    "    if len(new_decompressed) < len(decompressed):\n",
    "        diff = len(decompressed) - len(new_decompressed)\n",
    "        new_decompressed += b' ' * diff  # pad with spaces\n",
    "\n",
    "    # Recompress the new decompressed data\n",
    "    new_stream = zlib.compress(new_decompressed)\n",
    "\n",
    "    # Adjust padding if the compressed stream length doesn't match original.\n",
    "    attempts = 0\n",
    "    while len(new_stream) != original_length and attempts < 100:\n",
    "        if len(new_stream) < original_length:\n",
    "            # If too short, add one more space to the decompressed data.\n",
    "            new_decompressed += b' '\n",
    "        else:\n",
    "            # If too long, try removing trailing spaces.\n",
    "            new_decompressed = new_decompressed.rstrip(b' ')\n",
    "        new_stream = zlib.compress(new_decompressed)\n",
    "        attempts += 1\n",
    "\n",
    "    if len(new_stream) != original_length:\n",
    "        raise Exception(f\"Could not adjust stream length after {attempts} attempts \"\n",
    "                        f\"({len(new_stream)} != {original_length})\")\n",
    "\n",
    "    return header, new_stream\n",
    "\n",
    "def make_pdf_honeytoken(template: Path, output: Path, replacement: bytes) -> None:\n",
    "    \"\"\"\n",
    "    Creates a honeytoken PDF by reading a template PDF, replacing a placeholder in a\n",
    "    content stream with a tracking token (replacement), and writing the modified PDF.\n",
    "    \"\"\"\n",
    "    # Read the entire template PDF into memory\n",
    "    with open(template, \"rb\") as fp:\n",
    "        contents = fp.read()\n",
    "\n",
    "    # Extract the stream length from the PDF using a regex.\n",
    "    # This example looks for a pattern like \"/Length 1234\" starting from STREAM_OFFSET.\n",
    "    match = re.search(rb\".*?/Length\\s+([0-9]+)\", contents[STREAM_OFFSET:])\n",
    "    if not match:\n",
    "        raise Exception(\"Could not find stream length in template\")\n",
    "    stream_length = int(match.group(1))\n",
    "\n",
    "    # Find where the stream data starts.\n",
    "    # We assume the stream starts after \"stream\\r\\n\".\n",
    "    stream_marker = b\"stream\\r\\n\"\n",
    "    try:\n",
    "        stream_start = STREAM_OFFSET + contents[STREAM_OFFSET:].index(stream_marker) + len(stream_marker)\n",
    "    except ValueError:\n",
    "        raise Exception(\"Could not find stream marker in template\")\n",
    "\n",
    "    # Split the PDF into three parts:\n",
    "    # 1. Before the stream (from start of file to STREAM_OFFSET)\n",
    "    # 2. The stream itself (from stream_start to stream_start + stream_length)\n",
    "    # 3. The remainder of the file.\n",
    "    header = contents[STREAM_OFFSET:stream_start]\n",
    "    stream_data = contents[stream_start:stream_start + stream_length]\n",
    "    footer = contents[stream_start + stream_length:]\n",
    "\n",
    "    # Substitute the placeholder with your honeytoken in the stream data.\n",
    "    new_header, new_stream = substitute_stream(header, stream_data, replacement)\n",
    "\n",
    "    # Reassemble the PDF file.\n",
    "    new_contents = contents[:STREAM_OFFSET] + new_header + new_stream + footer\n",
    "\n",
    "    # Write the modified PDF to output.\n",
    "    with open(output, \"wb\") as out_file:\n",
    "        out_file.write(new_contents)\n",
    " \n",
    "    print(f\"Honeytoken PDF created: {output}\")\n",
    "\n",
    "# Example usage:\n",
    "template_path = Path(\"/Users/nicolaiveiglinarends/dtu-honeypot-thesis/snare/snare/tests/pdf_template_honeytoken.pdf\")  # Your PDF template file containing PLACEHOLDER_TOKEN\n",
    "output_path = Path(\"/Users/nicolaiveiglinarends/dtu-honeypot-thesis/snare/snare/tests/honeytoken.pdf\")\n",
    "# Example replacement: a tracking URL or unique token.\n",
    "# Ensure the replacement is of appropriate length or allow the padding loop to adjust.\n",
    "replacement_token = b\"    \n",
    "\n",
    "make_pdf_honeytoken(template_path, output_path, replacement_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import requests, sys, json\n",
    "from typing import Optional, Dict\n",
    "\n",
    "TOKENS_URL='https://canarytokens.org'\n",
    "\n",
    "def _gen_req_data(type: str, email: str, memo: str) -> Dict[str, str]:\n",
    "    return {\n",
    "        'type': type,\n",
    "        'email': email,\n",
    "        'memo': memo,\n",
    "        'fmt': '',\n",
    "        'webhook': '',\n",
    "        'redirect_url': '',\n",
    "        'cmd_process': '',\n",
    "        'azure_id_cert_file_name': '',\n",
    "        'clonedsite': '',\n",
    "        'sql_server_table_name': 'TABLE1',\n",
    "        'sql_server_view_name': 'VIEW1',\n",
    "        'sql_server_function_name': 'FUNCTION1',\n",
    "        'sql_server_trigger_name': 'TRIGGER1'\n",
    "    }\n",
    "\n",
    "def get_pdf_token(email : str, memo : str) -> Optional[str]:\n",
    "    '''\n",
    "    Returns a web bug token URL given an email and memo\n",
    "    '''\n",
    "    req_data = _gen_req_data('pdf', email, memo)\n",
    "    res = requests.post(TOKENS_URL + '/generate', data=req_data)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"Error: {res.status_code} - {res.text}\", file=sys.stderr)\n",
    "        return None\n",
    "    \n",
    "    return res.json().get('token_url', None)\n",
    "\n",
    "def get_aws_token(email : str, memo: str) -> Optional[Dict[str, str]]:\n",
    "    '''\n",
    "    Returns a dict of an AWS access key given an email and memo\n",
    "    '''\n",
    "    req_data = _gen_req_data('aws_keys', email, memo)\n",
    "    res = requests.post(TOKENS_URL + '/generate', data=req_data)\n",
    "    if res.status_code != 200:\n",
    "        return None\n",
    "    return {'access_key': res.json().get('aws_access_key_id'), 'secret_key': res.json().get('aws_secret_access_key')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: 400 - {\"error\":\"1\",\"error_message\":\"Malformed request, invalid data supplied.\",\"url\":\"\",\"url_components\":null,\"token\":\"\",\"email\":\"\",\"hostname\":\"\",\"auth\":\"\"}\n"
     ]
    }
   ],
   "source": [
    "response = get_pdf_token(\"  \", \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "TOKENS_URL='https://canarytokens.org'\n",
    "TOKENS_DOWNLOAD_URL = 'https://canarytokens.org/d3aece8093b71007b5ccfedad91ebb11/download'\n",
    "\n",
    "def generate_token(type: str, memo : str, webhook: str = ''):\n",
    "    '''\n",
    "    Returns a web bug token URL given an email and memo\n",
    "    '''\n",
    "    req_data = {\n",
    "        'type': type,\n",
    "        'memo': memo,\n",
    "        'webhook_url': webhook\n",
    "    }\n",
    "    res = requests.post(TOKENS_URL + '/generate', data=req_data)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"Error: {res.status_code} - {res.text}\")\n",
    "        return None\n",
    "    return res.json()\n",
    "\n",
    "def _downloaded_token_file(self, type: str, auth: str, token: str):\n",
    "\n",
    "    # Map the file type to the correct fmt\n",
    "    file_extensions = {\n",
    "        'adobe_pdf': 'pdf',\n",
    "        'ms_word': 'msword',\n",
    "        'ms_excel': 'msexcel',\n",
    "    }\n",
    "    fmt = file_extensions.get(type)\n",
    "    if not fmt:\n",
    "        print(f\"Unsupported file type: {type}\", \"ERROR\")\n",
    "        return None\n",
    "    \n",
    "    # Define the download URL parameters\n",
    "    params = {\n",
    "        'fmt': fmt,\n",
    "        'auth': auth,\n",
    "        'token': token\n",
    "    }\n",
    "    # Make the GET request to download the file\n",
    "    response = requests.get(TOKENS_DOWNLOAD_URL, params=params, allow_redirects=True)\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        print(f\"File content successfully downloaded\", \"INFO\")\n",
    "        return response.content\n",
    "    else:\n",
    "        print(f\"Failed to download content: {response.status_code} - {response.text}\", \"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 400 - {\"error\":\"1\",\"error_message\":\"Malformed request, invalid data supplied.\",\"url\":\"\",\"url_components\":null,\"token\":\"\",\"email\":\"\",\"hostname\":\"\",\"auth\":\"\"}\n"
     ]
    }
   ],
   "source": [
    "data = generate_token(\"adobe_pdf\", \"PDF - Triggered\", webhook=\"http://localhost:5003/webhook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': '  ',\n",
       " 'hostname': '  .canarytokens.net',\n",
       " 'token_url': 'http://canarytokens.com/terms/  /post.jsp',\n",
       " 'auth_token': '1b54dbabf49178271bdf84f3ce28cdef',\n",
       " 'email': '',\n",
       " 'webhook_url': '',\n",
       " 'url_components': [['articles',\n",
       "   'terms',\n",
       "   'feedback',\n",
       "   'tags',\n",
       "   'images',\n",
       "   'stuff',\n",
       "   'about',\n",
       "   'static',\n",
       "   'traffic'],\n",
       "  ['submit.aspx', 'contact.php', 'payments.js', 'index.html', 'post.jsp']],\n",
       " 'error': None,\n",
       " 'error_message': None,\n",
       " 'Url': None,\n",
       " 'token_type': 'adobe_pdf'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_downloaded_token_file(ty):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
